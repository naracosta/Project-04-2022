{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN (lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Process\n",
    "- What question are we trying to answer? \n",
    "- find data to help answer question \n",
    "- Process data\n",
    "- Build Model \n",
    "- Evaluate Model \n",
    "- Improve Model Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1E5ZR1Z4OQJG\", \"asin\": \"1495329321\", \"reviewerName\": \"Pure Jonel \\\"Pure Jonel\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\", \"overall\": 4.0, \"summary\": \"An amazing first novel\", \"unixReviewTime\": 1396137600, \"reviewTime\": \"03 30, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name= './dataframes/SKLEARN/Books_small.json' #caminho do arquivo json\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        print(line) # vai printar a primeira linha do json (no seu arquivo)\n",
    "        break  #para o loop em apenas uma linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "file_name= './dataframes/SKLEARN/Books_small.json' #caminho do arquivo json\n",
    "\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #usado para converter json string no python\n",
    "        print(review['reviewText']) #vai printar apenas a coluna de review\n",
    "        print(review['overall']) #vai printar a coluna de nota\n",
    "        \n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "abacaxi\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    \n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text #atributo texto \n",
    "        self.score = score  #atributo score \n",
    "        self.sentiment = self.get_sentiment() #sentimento da classe\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <=2:\n",
    "            #return \"NEGATIVE\" #é uma forma de retornar negativo, mas vamos usar outra levando em consideração a classe sentiment\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #score 4 ou 5\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "sentimento = Review(\"abacaxi\", 5)\n",
    "print(sentimento.sentiment)\n",
    "print(sentimento.text)\n",
    "print(sentimento.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "4.0\n",
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n"
     ]
    }
   ],
   "source": [
    "file_name= './dataframes/SKLEARN/Books_small.json' #caminho do arquivo json\n",
    "\n",
    "reviews = [] #criando uma lista vazia chamada reviews (onde vai ser adicionado os valores do loop)\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #usado para converter json string no python\n",
    "        reviews.append(Review(review['reviewText'], review['overall'])) #vai adicionar na lista valores de cada linha do json que serão delimitados por '()' #o Review é uma classe onde o primeiro termo é text e o segundo termo é o score (que é exatamente o que colocamos dentro dele)\n",
    "        \n",
    "#reviews[0:2]  #mostra o item 0 e o item 1\n",
    "print(reviews[5].sentiment)  #mostra o score da classe da linha 5 (se vc mudar para text, vai mostrar o texto de review)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numerical vectors (Prep Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procurar no google: sklearn train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42) #dica: shift+tab mostra os parametro que irão dentro da função\n",
    "#test_size: 0,33% das reviews serão teste o os 66% serão treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "670\n",
      "330\n",
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews)) #vai contar o numero de reviews que tem na lista que vc criou (que vai se o numero de review da sua base de dados)\n",
    "print(len(training)) #anteriormente vc separou 66% dos seus dados para treinamento\n",
    "print(len(teste))#anteriormente vc separou 33% dos seus dados para teste\n",
    "\n",
    "print(training[0].text) #vai imprimir o primeiro texto que será treinado\n",
    "print(training[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n",
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "train_x = [x.text for x in training] #vai pegar todos os textos de treinamento e colocar numa lista\n",
    "train_y = [x.sentiment for x in training] #vai pegar todos os sentimentos de treinamento e colocar numa lista\n",
    "\n",
    "test_x = [x.text for x in test]#vai pegar todos os textos de teste e colocar numa lista\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0]) #vai mostrar o primeiro item da lista de treinamento\n",
    "print(train_y[0])\n",
    "print(test_x[0])#vai mostrar o primeiro item da lista de teste\n",
    "print(test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words vectorization (Extrair recursos de arquivos de texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "  (0, 7086)\t1\n",
      "  (0, 1148)\t1\n",
      "  (0, 350)\t2\n",
      "  (0, 1800)\t1\n",
      "  (0, 6595)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 3054)\t1\n",
      "  (0, 1558)\t1\n",
      "  (0, 6475)\t1\n",
      "  (0, 6593)\t1\n",
      "  (0, 2895)\t1\n",
      "  (0, 7353)\t1\n",
      "  (0, 539)\t1\n",
      "  (0, 1515)\t1\n",
      "  (0, 5197)\t1\n",
      "  (0, 3545)\t1\n",
      "  (0, 2007)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() # mais informações: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0]) #Essa matriz representa a vetorização dos caracters que estão na linha zero do train_x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0]) #mensagem de texto\n",
    "print(train_x_vectors[0].toarray()) #mensagem de texto transformada em vetor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear') #kernel executa e analisa o código do usuário\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y) #esse comando vai fazer o classificador SVM treinar os dados \n",
    "\n",
    "test_x[0] #mostra o texto contido na linha 0\n",
    "#train_x_vectors[0]\n",
    "clf_svm.predict(train_x_vectors[0]) #mostra a previsão do sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "clf_dec.predict(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB ## *******\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_gnb.predict(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aluga.com\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3596bf6bd313b0d54e77ecee54a840c3d36cdd605cf756522bad1862e906968"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
